# LOCAL-RAG-LLM
##created an local rag +llm using embedding functions,vector database and gemma-2b for llm and also an alternative,using openai api and also used streamlit for front end

##how to intialize?

copy the files from the repositry and load them up in vscode
2.set open ai api key or hugging face api(make sure u have access to gemma-2b model)
##thats it open terminal and run commands pip install -r requirmetns.txt and enter command streamlit run v3.py
